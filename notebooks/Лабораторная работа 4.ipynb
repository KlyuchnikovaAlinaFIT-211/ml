{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d68de6",
   "metadata": {
    "id": "13d68de6"
   },
   "source": [
    "# Лабораторная работа 4. Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f92923",
   "metadata": {
    "id": "e9f92923"
   },
   "source": [
    "## Искусственные нейроны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a07e2",
   "metadata": {
    "id": "8d1a07e2"
   },
   "source": [
    "Искусственными нейронными сетями (чаще - просто нейронными сетями) называются модели машинного обучения, в основе функционирования которых лежат <b>принципы работы биологических нейронов</b> в человеческом мозге. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8517f9",
   "metadata": {
    "id": "fa8517f9"
   },
   "source": [
    "Идея, лежащая в основе нейронных сетей, очень простая: каждый биологический нейрон имеет несколько входов (дендритов), на основе информации с которых формируется выходной сигнал, который с помощью выхода (аксона) передается далее к органам человеческого (и не только) организма. В 1943 году У. Маккалок и У. Питтс предложили идею искусственного нейрона."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8fb4c",
   "metadata": {
    "id": "7ea8fb4c"
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/ru/thumb/b/ba/Single_layer_perceptron.png/270px-Single_layer_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f99850",
   "metadata": {
    "id": "38f99850"
   },
   "source": [
    "Искусственный нейрон также имеет дендриты и аксон. Математически, здесь на вход нейрона подается некоторый вектор из чисел $x$. При этом каждый дендрит имеет свой вес $w$. Значение нейрона $h$ вычисляется как $h=wx^T$, если в векторной форме. А если в скалярной, то речь идет о простом перемножении компонент входного вектора на соответствующие веса связей и последующее суммирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e50bf",
   "metadata": {
    "id": "7c1e50bf"
   },
   "source": [
    "Заметим, что такой нейрон полностью эквивалентен линейному регрессору, а это значит, что он может находить в данных исключительно линейные зависимости. Чтобы такого не было придумали передавать аксону не $h$, а $f(h)$, где $f$ - нелинейная функция, называемая <b>функцией активации</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41ff97",
   "metadata": {
    "id": "7f41ff97"
   },
   "source": [
    "Функции активации способны управлять множеством значений нейрона. Ниже приведены некоторые функции активации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf033d03",
   "metadata": {
    "id": "bf033d03"
   },
   "source": [
    "![](https://programforyou.ru/images/useful/cnn/part0/activations.png?v=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a4f37",
   "metadata": {
    "id": "d67a4f37"
   },
   "source": [
    "## Полносвязные нейронные сети. Получение предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2cce9",
   "metadata": {
    "id": "52a2cce9"
   },
   "source": [
    "Со временем идея искусственных нейронов была обобщена. Появились модели, в которых уже присутствовало несколько взаимосвязанных между собой нейронов. Исторически первым прикладным обобщением сетей из искусственных нейронов является <b>многослойный персептрон</b>. Его концепция была предложена Ф. Розенблатом в 1958 году. Однако персептрон Розенблата имел всего три слоя. Мы же будем рассматривать обобщенную модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046b4bb",
   "metadata": {
    "id": "d046b4bb"
   },
   "source": [
    "![](https://neerc.ifmo.ru/wiki/images/thumb/6/63/Multi-layer-neural-net-scheme.png/500px-Multi-layer-neural-net-scheme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7d5d8",
   "metadata": {
    "id": "6ea7d5d8"
   },
   "source": [
    "Представленая выше нейронная сеть (многослойный персептрон) называется <b>полносвязной</b>. Это означает, что каждый нейрон текущего слоя связан с каждым нейроном предыдущего слоя. Если скрытых нейронов больше чем один, то такая сеть называется <b>глубокой</b>. Обучение глубоких нейронных сетей называется глубоким обучением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485ea9e",
   "metadata": {
    "id": "4485ea9e"
   },
   "source": [
    "В сети выделяют входной слой (нейроны, на которых просто размещается вектор входных значений), скрытые слои (у каждого слоя своя функция активации, которую используют все нейроны) и выходной слой (функция активации выходного слоя отображает значения суммы в требуемое множество значений). Вы, наверное, догадались, что в случае регрессии функция активации выходного слоя, как правило, не ограничивает значения нейронов (то есть может вообще не применяться), может отображать значения нейрона в положительное число (например, relu). В случае классификации в большинстве случаев используются функции активации sigmoid и softmax. Как именно они применяются вы увидите на практике ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c0722",
   "metadata": {
    "id": "ad3c0722"
   },
   "source": [
    "Получение предсказаний с помощью нейронной сети - это <b>процесс последовательного выполнения матричного умножения с последующим поэлементным применением функции активации к получившемуся вектору<b>. Не верите? давайте это увидим."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc34f6",
   "metadata": {
    "id": "d5dc34f6"
   },
   "source": [
    "Каждому слою сети (кроме входного) соответствует матрица обучаемых параметров. Пусть мы рассматриваем первых скрытый слой, обозначим количество его нейронов за $m$. Обозначим количество нейронов предыдущего слоя (входного) за $n$. Тогда матрица весов слоя $W$ будет иметь размерность $m{\\times}n$. Элемент $w_{ij}$ - вес связи $i$ нейрона текущего слоя с $j$ нейроном предыдущего."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c1622",
   "metadata": {
    "id": "442c1622"
   },
   "source": [
    "Также каждому слою соответствует собственный вектор $b$ - это значение сдвига. Количество элементов вектора b соответствует количеству нейронов текущего слоя. Значения нейронов текущего слоя $h$ вычисляется как $h=Wx+b$. Выходное значение нейронов вычисляется как $f(h)$, где $f$ - функция активации текущего слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a2d7a",
   "metadata": {
    "id": "b63a2d7a"
   },
   "source": [
    "Как вы видите, получить предсказания очень просто. Изначально значения W и b каждого слоя инициализируются случайным образом. Вы понимаете, что для получения адекватных предсказаний нам необходимо выполнить обучение, то есть <b>найти значения W и b для каждого слоя сети, которые позволят минимизировать функцию ошибки</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7395af",
   "metadata": {
    "id": "4c7395af"
   },
   "source": [
    "## Обучение полносвязных нейронных сетей. Алгоритм обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431697ea",
   "metadata": {
    "id": "431697ea"
   },
   "source": [
    "Обучение нейронной сети производится с использованием подходов, в основе которых лежит градиентный спуск. В самом простом случае - это обычный, уже знакомый нам, метод наискорейшего спуска. Но вот задача - все эти методы требуют расчета градиента функции ошибки. А как нам посчитать градиент функции ошибки при использовании нейронной сети? Оказывается, что в этом случае мы не можем просто взять и посчитать сразу весь градиент. Вместо этого, мы можем вычислить его по отдельным частям. Алгоритм вычисления градиента, используемый при обучении нейронных сетей, получил название <b>метод обратного распространения ошибки (backpropagation)</b>. Понимание его работы - это основа вашего понимания работы нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a01ba",
   "metadata": {
    "id": "376a01ba"
   },
   "source": [
    "Суть метода обратного распространения ошибки заключается в том, что мы после получения конечных предсказаний начинаем идти назад (от последнего слоя к первому) и последовательно вычислять части градиента. Как вы, наверное, догадались, обучаемыми параметрами у нас являются $W$ и $b$ для каждого слоя. Мы двигаемся начиная с последнего слоя и последовательно вычисляем эти градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a241e8a",
   "metadata": {
    "id": "7a241e8a"
   },
   "source": [
    "Для того, чтобы нам удобно было все это понять, давайте каждый слой разобьем еще на два слоя. Для простоты сделаем так, что вся сеть имеет только входной слой и выходной (выходной разбит на два отдельных слоя)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a7d99",
   "metadata": {
    "id": "eb4a7d99"
   },
   "source": [
    "![](https://i.vgy.me/S1IeLk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e36a3e",
   "metadata": {
    "id": "a8e36a3e"
   },
   "source": [
    "Мы видим, что любую нейронную сеть таким образом можно разбить на большее количество слоев, если каждый слой с функцией активации разбить на два слоя. Представить, что на первом выполняется суммирование произведений (умножение матрицы на вектор и добавление сдвига), а на втором - поэлементное применение функции активации. Продолжая подобные рассуждения, мы придем к тому, что любая полносвязная сеть может быть представлена как набор последовательных компонентов, каждый из которых можно рассматривать как функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11839a14",
   "metadata": {
    "id": "11839a14"
   },
   "source": [
    "![](https://i.vgy.me/7vWpIw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3a7c6",
   "metadata": {
    "id": "05c3a7c6"
   },
   "source": [
    "Каждый такой компонент берет входные данные и преобразует их в выходные (в случае полносвязной нейронной сети компонент либо выполняет линейное преобразование, либо применяет функцию активации). Входные данные текущего блока являются выходными данными предыдущего. Но посмотрите, а что представляют собой тогда выходные данные последнего компонента с математической точки зрения? Это ни что иное, как результат применения <b>сложной функции</b> к входным данным. В данном случае, $y_3=f_3(f_2(f_1(x_1)))$. А теперь давайте вспомним, что каждый эти компоненты содержат обучаемые параметры $W$ и $b$. В данном случае у нас есть $W_1$ и $b_1$, а также $W_3$ и $b_3$ (второй компонент не содержит обучающих параметров, поскольку отвечает за просто поэлементное применение функции активации)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6d5ee",
   "metadata": {
    "id": "6be6d5ee"
   },
   "source": [
    "Но мы с вами ранее сказали о том, что градиент вычисляется частично и по каждому множеству обучаемых параметров, так? Да, все именно так. Мат. анализ предоставляет нам замечательный инструмент для вычисления производных сложной функции - <b>цепное правило (chain rule)</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7594ccb",
   "metadata": {
    "id": "f7594ccb"
   },
   "source": [
    "Суть цепного правила вы помните со школы: если $y=y(g(x))$, то ${\\frac{dy}{dx}}={\\frac{dy}{dg}}{\\frac{dg}{dx}}$. То же самое работает и в нашем случае. Каждый компонент использует значения частных производных функции потерь по своему выходу для непосредственного вычисления частных производных функции потерь по $W$ и $b$, а также передает предыдущему компоненту вычисленные значения производной функии потерь по своему входу. Далее компонент с использованием оптимизатора делает шаг градиентного спуска (обновляются значения весов $W$ и $b$). <b>Обращаю внимание: обновление весов выполняется ПОСЛЕ вычисления частных производных по весам</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dea9a2",
   "metadata": {
    "id": "82dea9a2"
   },
   "source": [
    "![sejsej](https://i.vgy.me/m5KKFF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd14a4",
   "metadata": {
    "id": "98fd14a4"
   },
   "source": [
    "Итак, пусть у нас задана функция потерь. Для регрессии и бинарной классификации можно использовать модифицированную MSE: $E={\\frac{1}{2}}(y-\\hat{y})^2$. Мы хотим ее минимизировать. Ранее мы буквой $L$ обозначали функцию потерь, а при работе с нейронными сетями устоялось обозначение $E$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca869d1e",
   "metadata": {
    "id": "ca869d1e"
   },
   "source": [
    "Осталось разобраться, по каким формулам вычисляются части градиента в каждом компоненте. Мы знаем, что в каждом компоненте вычисляется $\\frac{\\partial{E}}{\\partial{x}}$. В некоторых компонентах вычисляются $\\frac{\\partial{E}}{\\partial{W}}$ и $\\frac{\\partial{E}}{\\partial{b}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f597a",
   "metadata": {
    "id": "733f597a"
   },
   "source": [
    "Запишем формулы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6e1a1",
   "metadata": {
    "id": "dad6e1a1"
   },
   "source": [
    "$\\frac{\\partial{E}}{\\partial{W}}$ = $\\frac{\\partial{E}}{\\partial{y}}x^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2984a",
   "metadata": {
    "id": "abe2984a"
   },
   "source": [
    "$\\frac{\\partial{E}}{\\partial{b}}$ = $\\frac{\\partial{E}}{\\partial{y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66a9d5",
   "metadata": {
    "id": "dc66a9d5"
   },
   "source": [
    "Частные производные функции потерь по входу вычисляются по разному, в зависимости от назначения компонента. Если это компонент, реализующий линейное преобразование ($Wx+b$), то $\\frac{\\partial{E}}{\\partial{x}} = W^T\\frac{\\partial{E}}{\\partial{y}} $. Если это компонент, применяющий функцию активации $f$ (sigmoid, tanh, relu), то $\\frac{\\partial{E}}{\\partial{x}} = \\frac{\\partial{E}}{\\partial{y}}\\odot f'(x) $. $\\odot$ - это поэлементное произведение векторов (произведение Адамара). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122831c5",
   "metadata": {
    "id": "122831c5"
   },
   "source": [
    "Можно увидеть, что все функции активации слоев обязаны быть дифференцируемыми. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382aa47",
   "metadata": {
    "id": "0382aa47"
   },
   "source": [
    "При решении задач классификации (в общем случае, когда количество классов больше двух), как правило, применяется функция потерь перекрестная энтропия (при бинарной классификации применяется ее частный случай - бинарная перекрестная кросэнтропия). Выглядит она следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701bb5a",
   "metadata": {
    "id": "0701bb5a"
   },
   "source": [
    "Общий случай: $E = -\\sum_{k}^{s}{{y_k}ln{\\hat{y_k}}}$. Здесь s - количество классов. При использовании такой функции потерь, предполагается, что целевой признак размечен (например, для случая двух классов) как [1, 0]. Это оначает, что объект относится к 0 классу. Предположим, модель предсказала ответ [0,36, 0,64]. Она ошиблась. Можно посчитать значение перекрестной энтропии и обновить веса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea437c",
   "metadata": {
    "id": "d8ea437c"
   },
   "source": [
    "Как вы видите, использование перекрестной энтропии требует, чтобы сумма значений нейронов была единица и все числа были положительными. Для получения такого результата на произвольном слое с нейронами используется функция softmax. Ее можно назвать функцией активации, однако при использовании softmax $\\frac{\\partial{E}}{\\partial{x}}$ считается по другому. $\\frac{\\partial{E}}{\\partial{x}} = ((1-y^T)y)\\frac{\\partial{E}}{\\partial{y}} $. Подчеркну, что 1 здесь обозначена единичная матрица."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ebb36",
   "metadata": {
    "id": "647ebb36"
   },
   "source": [
    "Вот и все. Теперь вы можете реализовать собственную полносвязную нейронную сеть. Для облегчения задачи представьте ее в виде компонентов, как это описано выше. Чтобы начать вычисление градиента необходимо начать двигаться от последнего компонента к первому, при этом предварительно посчитать частную производную функции потерь по выходу последнего компонента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb42973",
   "metadata": {
    "id": "adb42973"
   },
   "source": [
    "## Использование фреймворка TensorFlow и API Keras для построеония нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b38f0",
   "metadata": {
    "id": "b08b38f0"
   },
   "source": [
    "Мы разобрались, как работают полносвязные нейронные сети. Давайте теперь решим задачи регрессии и классификации с помощью фреймворка TensorFlow. Начнем с загрузки предварительно обработанных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5340d31a",
   "metadata": {
    "id": "5340d31a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_regression = pd.read_csv(\"../data/trip_duration_task_obr.csv\").sample(20000).reset_index(drop=True)\n",
    "data_classification = pd.read_csv(\"../data/csgo_task_obr.csv\").sample(20000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d04b7d",
   "metadata": {
    "id": "a0d04b7d"
   },
   "outputs": [],
   "source": [
    "data_regression.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "data_classification.drop(columns = [\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6bc6d4",
   "metadata": {
    "id": "ef6bc6d4",
    "outputId": "61070045-2298-4c89-e866-2bf53ba5b41b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>pickup_mes</th>\n",
       "      <th>dropoff_mes</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>dropoff_day</th>\n",
       "      <th>pickup_chas</th>\n",
       "      <th>dropoff_chas</th>\n",
       "      <th>pickup_min</th>\n",
       "      <th>dropoff_min</th>\n",
       "      <th>pickup_sec</th>\n",
       "      <th>dropoff_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.981689</td>\n",
       "      <td>40.773441</td>\n",
       "      <td>-73.973442</td>\n",
       "      <td>40.764477</td>\n",
       "      <td>325</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-74.001534</td>\n",
       "      <td>40.741112</td>\n",
       "      <td>-73.982780</td>\n",
       "      <td>40.736301</td>\n",
       "      <td>444</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987411</td>\n",
       "      <td>40.747868</td>\n",
       "      <td>-73.972748</td>\n",
       "      <td>40.755798</td>\n",
       "      <td>389</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980545</td>\n",
       "      <td>40.754211</td>\n",
       "      <td>-73.984917</td>\n",
       "      <td>40.748165</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.968216</td>\n",
       "      <td>40.762424</td>\n",
       "      <td>-73.978851</td>\n",
       "      <td>40.765186</td>\n",
       "      <td>887</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "0        1.0                1        -73.981689        40.773441   \n",
       "1        2.0                2        -74.001534        40.741112   \n",
       "2        1.0                1        -73.987411        40.747868   \n",
       "3        1.0                1        -73.980545        40.754211   \n",
       "4        1.0                2        -73.968216        40.762424   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  trip_duration  pickup_mes  \\\n",
       "0         -73.973442         40.764477            325           3   \n",
       "1         -73.982780         40.736301            444           6   \n",
       "2         -73.972748         40.755798            389           5   \n",
       "3         -73.984917         40.748165            193           1   \n",
       "4         -73.978851         40.765186            887           4   \n",
       "\n",
       "   dropoff_mes  pickup_day  dropoff_day  pickup_chas  dropoff_chas  \\\n",
       "0            3          10           10            7             7   \n",
       "1            6          11           11           23            23   \n",
       "2            5          13           13            5             5   \n",
       "3            1          12           12           19            19   \n",
       "4            4          21           21           10            11   \n",
       "\n",
       "   pickup_min  dropoff_min  pickup_sec  dropoff_sec  \n",
       "0          28           34          40            5  \n",
       "1          22           29          22           46  \n",
       "2          12           18           0           29  \n",
       "3          18           21          28           41  \n",
       "4          58           13          58           45  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df0807a",
   "metadata": {
    "id": "9df0807a",
    "outputId": "6e1a6123-a978-4278-fd47-6834d9096dfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_left</th>\n",
       "      <th>ct_score</th>\n",
       "      <th>t_score</th>\n",
       "      <th>bomb_planted</th>\n",
       "      <th>ct_health</th>\n",
       "      <th>t_health</th>\n",
       "      <th>ct_armor</th>\n",
       "      <th>t_armor</th>\n",
       "      <th>ct_money</th>\n",
       "      <th>t_money</th>\n",
       "      <th>ct_helmets</th>\n",
       "      <th>t_helmets</th>\n",
       "      <th>ct_defuse_kits</th>\n",
       "      <th>ct_players_alive</th>\n",
       "      <th>t_players_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.93</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>False</td>\n",
       "      <td>200.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>17950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.95</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_left  ct_score  t_score  bomb_planted  ct_health  t_health  ct_armor  \\\n",
       "0      89.93       9.0     12.0         False      200.0     500.0       0.0   \n",
       "1     106.87      13.0     11.0         False      500.0     500.0     490.0   \n",
       "2      69.97       2.0      2.0         False      500.0     500.0     500.0   \n",
       "3     114.95       9.0      5.0         False      500.0     500.0     300.0   \n",
       "4     114.94       0.0      1.0         False      500.0     500.0     500.0   \n",
       "\n",
       "   t_armor  ct_money  t_money  ct_helmets  t_helmets  ct_defuse_kits  \\\n",
       "0    500.0    5400.0  17950.0         0.0        5.0             0.0   \n",
       "1    500.0   12800.0   5300.0         5.0        5.0             4.0   \n",
       "2    450.0     300.0  13750.0         1.0        5.0             0.0   \n",
       "3    200.0     750.0   1100.0         0.0        0.0             1.0   \n",
       "4    500.0    2500.0    650.0         3.0        5.0             0.0   \n",
       "\n",
       "   ct_players_alive  t_players_alive  \n",
       "0               2.0              5.0  \n",
       "1               5.0              5.0  \n",
       "2               5.0              5.0  \n",
       "3               5.0              5.0  \n",
       "4               5.0              5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc58fb63",
   "metadata": {
    "id": "dc58fb63"
   },
   "outputs": [],
   "source": [
    "y_regression = data_regression[\"trip_duration\"]\n",
    "X_regression = data_regression.drop(columns = ['trip_duration'])\n",
    "y_classification = data_classification['bomb_planted']\n",
    "X_classification = data_classification.drop(columns = ['bomb_planted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cf5839",
   "metadata": {
    "id": "f5cf5839"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_regression_train, X_regression_test, y_regression_train, y_regression_test = train_test_split(X_regression,\n",
    "                                                                                                y_regression,\n",
    "                                                                                                test_size=0.2)\n",
    "X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(X_classification,\n",
    "                                                                                                                y_classification,\n",
    "                                                                                                                stratify=y_classification,\n",
    "                                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84f4fc",
   "metadata": {
    "id": "9b84f4fc"
   },
   "source": [
    "Импортируем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda21ed2",
   "metadata": {
    "id": "fda21ed2"
   },
   "outputs": [],
   "source": [
    "# для оценки качества решения задачи регрессии\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# для оценки качества решения задачи классификации\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078d1a1c",
   "metadata": {
    "id": "078d1a1c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49610a3",
   "metadata": {
    "id": "f49610a3"
   },
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e563d4d",
   "metadata": {
    "id": "0e563d4d"
   },
   "source": [
    "Создаем полносвязную нейронную сеть для решения задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c73d33",
   "metadata": {
    "id": "b3c73d33"
   },
   "outputs": [],
   "source": [
    "# создаем модель, как набор последовательных слоев\n",
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(16,)),\n",
    "        # на втором скрытом слое будет 32 нейрона\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # на выходе один нейрон, функция активации не применяется\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af49e8d0",
   "metadata": {
    "id": "af49e8d0",
    "outputId": "eaee9795-f3d3-4e99-d4f3-f218f0440c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,713\n",
      "Trainable params: 3,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, какая сеть у нас получилась\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c118e",
   "metadata": {
    "id": "f04c118e"
   },
   "source": [
    "Видим количество обучаемых параметров каждого слоя и общее количество обучаемых параметров. Перед использованием модель необходимо скомпилировать, при этом указывается оптимизатор, скорость обучения (можно представлять как величину шага в методе градиентного спуска), функция потерь и метрики, которые мы хотим (при желании) вычислять в будущем методом evaluate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ebc13f",
   "metadata": {
    "id": "11ebc13f"
   },
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bfe2ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_classification_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d03d027",
   "metadata": {
    "id": "5d03d027",
    "outputId": "66fc9b4f-897f-4f1d-b43d-0699ba361f00",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 4s 4ms/step - loss: 9129292.0000\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 9084909.0000\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 9071501.0000\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 9043495.0000\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8960631.0000\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8929738.0000\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8938377.0000\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8921349.0000\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8927380.0000\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8916144.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2660c041e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
    "model_regression.fit(X_regression_train, y_regression_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fe0b9d4",
   "metadata": {
    "id": "2fe0b9d4",
    "outputId": "5e2c5afc-20ba-44c0-b3a4-c7417f1d97fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 3ms/step\n",
      "539.3775071105957\n",
      "125/125 [==============================] - 0s 3ms/step\n",
      "16145649.249481533\n"
     ]
    }
   ],
   "source": [
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399f5ba",
   "metadata": {
    "id": "5399f5ba"
   },
   "source": [
    "Мы получили наглядную демонстрацию важного факта - в некоторых задачах применение нейронных сетей менее целесообразно, чем использование более простых моделей. Но иногда они дают лучшие результаты. Важную роль еще играет подбор архитектуры и параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838f599",
   "metadata": {
    "id": "4838f599"
   },
   "source": [
    "### Бинарная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c0f56",
   "metadata": {
    "id": "9b5c0f56"
   },
   "source": [
    "Нейронная сеть для решения задачи классификации будет очень похожа на ту сеть для регрессии, однако у нее по другому будет организован выходной слой. У нас есть 2 стратегии наполнения выходного слоя нейронами:\n",
    "\n",
    "- при решении задачи бинарной классификации мы можем расположить на выходном слое один нейрон с функцией активации sigmoid (значения от 0 и 1), после чего округлять полученные значения; значение нейрона покажет уверенность сети в предсказании; также мы можем расположить 2 нейрона на выходном слое и применить функцию softmax. Тогда сумма значений нейронов выходного слоя будет 1, а предсказание мы сможем получить определив нейрон с наибольшим значением;\n",
    "- в случае многоклассовой классификации, как правило, на выходном слое располагаются k нейронов (по количеству классов), функция активации - softmax; нейрон с наибольшим значением определяет предсказанный класс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc09fe",
   "metadata": {
    "id": "cfdc09fe"
   },
   "source": [
    "У нас задача бинарной классификации, попробуем обе стратегии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66cf4a4",
   "metadata": {
    "id": "a66cf4a4",
    "outputId": "b4c9aa05-6b9f-44e8-8086-03a87f6aa200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2660c7dc5b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(14,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # сначала используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "# в качестве функции активации используется бинарная  кроссэнтропия\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# verbose=None - не будет логов\n",
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e63257",
   "metadata": {
    "id": "46e63257"
   },
   "source": [
    "Посмотрим, как выглядят предсказания сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18172a49",
   "metadata": {
    "id": "18172a49",
    "outputId": "5788d18f-ecc8-44f1-950a-cf5d4445dfdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1.predict(X_classification_test, verbose=None)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5c89e",
   "metadata": {
    "id": "8ef5c89e"
   },
   "source": [
    "Это числа от 0 до 1, поскольку мы использовали sigmoid. Для того, чтобы получить финальное предсказания классов, необходимо округлить все полученные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "161a4c98",
   "metadata": {
    "id": "161a4c98",
    "outputId": "3fcfcaa3-650b-431c-d32b-d5626fa9ee0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      1.00      0.94      3567\n",
      "        True       0.00      0.00      0.00       433\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.45      0.50      0.47      4000\n",
      "weighted avg       0.80      0.89      0.84      4000\n",
      "\n",
      "[[3567    0]\n",
      " [ 433    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\machine_learning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\machine_learning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\machine_learning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b27da",
   "metadata": {
    "id": "048b27da"
   },
   "source": [
    "Обратите внимание, что дисбаланс классов может привести к неудовлетворительным результатам обучения модели. Необходимо сбалансировать обучающую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc4e63",
   "metadata": {
    "id": "43bc4e63"
   },
   "source": [
    "Но, даже без выполнения балансировки, можно взвесить функцию потерь. Можем указать веса (параметр class_weight), которые будут использоваться при оптимизации функции ошибки. В качестве весов классов можно задать величины, обратные количеству элементов класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df16179e",
   "metadata": {
    "id": "df16179e"
   },
   "outputs": [],
   "source": [
    "w0 = 1 / y_classification_train[y_classification_train==0].shape[0]\n",
    "w1 = 1 / y_classification_train[y_classification_train==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efce734",
   "metadata": {
    "id": "1efce734",
    "outputId": "afe7e5f2-f0c2-45a3-f63b-7c61208df0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.88      0.94      3567\n",
      "        True       0.50      0.99      0.66       433\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.75      0.94      0.80      4000\n",
      "weighted avg       0.94      0.89      0.91      4000\n",
      "\n",
      "[[3137  430]\n",
      " [   4  429]]\n"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(14,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})\n",
    "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e3660",
   "metadata": {
    "id": "370e3660"
   },
   "source": [
    "Видим улучшения. Можем поиграть с архитектурой и параметрами и добиться еще более качественных результатов. Но напоследок давайте попробуем разместить 2 нейрона на выходном слое и использовать softmax в качестве функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd17e1c4",
   "metadata": {
    "id": "cd17e1c4",
    "outputId": "56b71377-8862-48d7-d8fb-4829c6ca224c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2660f02a040>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(14,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # сначала используем 2 нейрона и softmax\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "# в качестве функции активации используется категориальная кроссэнтропия\n",
    "# используем разряженный (sparse) вариант, поскольку значения целевого признака не закодированы One-Hot кодированием\n",
    "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
    "model_classification_2.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34b44a42",
   "metadata": {
    "id": "34b44a42",
    "outputId": "d34e5d71-0e72-4ab9-ca6c-1af9d6826d73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9934572e-01, 6.5423123e-04],\n",
       "       [8.4924287e-01, 1.5075709e-01],\n",
       "       [9.9856073e-01, 1.4392918e-03],\n",
       "       [9.9965966e-01, 3.4036476e-04],\n",
       "       [9.9142754e-01, 8.5724825e-03]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2.predict(X_classification_test, verbose=None)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f88855",
   "metadata": {
    "id": "c2f88855"
   },
   "source": [
    "Каждое предсказание - это два числа (потому что два нейрона). Сумма значений равна 1. Каждое значение можно интерпретировать как вероятность отнесения объекта к соответствующему классу (0 или 1). Воспользуемся функцией argmax для того, чтобы получить итоговые предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2143a1ef",
   "metadata": {
    "id": "2143a1ef"
   },
   "outputs": [],
   "source": [
    "# получим индексы максимального значения для каждого элемента (вложенный массив) с помощью numpy\n",
    "y_pred = [np.argmax(pred) for pred in model_classification_2.predict(X_classification_test, verbose=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87091ba5",
   "metadata": {
    "id": "87091ba5",
    "outputId": "4ed37b0f-dc35-4c5a-ab0b-51bee6776817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.91      0.95      3567\n",
      "        True       0.56      0.97      0.71       433\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.78      0.94      0.83      4000\n",
      "weighted avg       0.95      0.92      0.92      4000\n",
      "\n",
      "[[3240  327]\n",
      " [  11  422]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469c34e",
   "metadata": {
    "id": "2469c34e"
   },
   "source": [
    "Когда мы закончили обучение моделей, мы можем сохранить их на диск, чтобы в будущем либо продолжить обучение (если оно занимает много времени) или использовать для получения предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a0ea2e8",
   "metadata": {
    "id": "5a0ea2e8",
    "outputId": "67fdc99e-ce2c-4a6d-b174-2e324a94270c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_regression.save('../models/RegressionModel')\n",
    "model_classification_1.save('../models/ClassificationModel1')\n",
    "model_classification_2.save('../models/ClassificationModel2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc0974",
   "metadata": {
    "id": "29fc0974"
   },
   "source": [
    "Модели сохранены в виде папки. Теперь, когда они нам потребуются, можем очень просто их загрузить. Загрузим, например, модель для регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cefa072",
   "metadata": {
    "id": "2cefa072",
    "outputId": "2696f2a6-5c3c-47ea-a885-e7a5f4877500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,713\n",
      "Trainable params: 3,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression_restored = tf.keras.models.load_model('../models/RegressionModel')\n",
    "model_regression_restored.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58c837c5",
   "metadata": {
    "id": "58c837c5",
    "outputId": "2f11651c-6436-4423-f520-322df13da4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539.3775071105957\n",
      "16145649.249481533\n"
     ]
    }
   ],
   "source": [
    "# используем модель\n",
    "print(mean_absolute_error(y_regression_test, model_regression_restored.predict(X_regression_test, verbose=None)))\n",
    "print(mean_squared_error(y_regression_test, model_regression_restored.predict(X_regression_test, verbose=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gW-NhwXEChTS",
   "metadata": {
    "id": "gW-NhwXEChTS"
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-IPcUj1UCeIz",
   "metadata": {
    "id": "-IPcUj1UCeIz"
   },
   "source": [
    "<b>Традиционное предупреждение для всех лабораторных работ:</b> перед обучением моделей необходимо выполнить предварительную обработку данных, которая <b>обязательно</b> включает в себя:\n",
    "- заполнение пропущенных значений (рекомедуется логика заполнения пропусков на основе типа данных, которая использовалась в РГР по Практикуму);\n",
    "- преобразование категориальных признаков в числовые (используйте one-hot кодирование или map; используйте знания с Практикума)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jcfIwITzCgTb",
   "metadata": {
    "id": "jcfIwITzCgTb"
   },
   "source": [
    "Предобработка может включать в себя другие действия, но выполнение описанных выше действий обязательно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H8y4nWluCkgr",
   "metadata": {
    "id": "H8y4nWluCkgr"
   },
   "source": [
    "Сделайте это один раз и сохраните в отдельный csv файл, а потом его используйте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T24SZSN1CmBL",
   "metadata": {
    "id": "T24SZSN1CmBL"
   },
   "source": [
    "<b>Выполните следующие задания:</b>\n",
    "- решите задачи регрессии и классификации на ваших данных используя полносвязные нейронные сети; соберите их используя API Keras фреймворка TensorFlow; оцените качество полученных моделей с помощью метрик; \n",
    "- реализуйте многослойный персептрон, с помощью которого можно решать задачи регрессии и классификации; предусмотрите возможность использовать такие функции активации, как sigmoid, tanh и relu; также предусмотрите возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой; реализуйте обучение персептрона методом обратного распространения ошибки; самостоятельно найдите производные функций sigmoid, tanh и relu; реализуйте классический градиентный спуск с возможностью указания шага.\n",
    "\n",
    "<b>Дополнительные задания:</b>\n",
    "- самостоятельно изучите отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска; реализуйте градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптимизаторов в вашем персептроне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ozjLqw6KCoSK",
   "metadata": {
    "id": "ozjLqw6KCoSK"
   },
   "outputs": [],
   "source": [
    "class Perseptron:\n",
    "    \n",
    "    def relu(t):\n",
    "        return np.maximum(t,0)\n",
    "    def sigmoid(t):\n",
    "        return 1/(1+np.exp(-t))\n",
    "    def tanh(t):\n",
    "        return np.tanh(t)\n",
    "    def softmax(t):\n",
    "        out = np.exp(t)\n",
    "        return out/np.sum(out)\n",
    "    def linear(t):\n",
    "        return t\n",
    "    func_activaits = {\n",
    "        'relu': relu,\n",
    "        'sigmoid': sigmoid,\n",
    "        'tanh': tanh,\n",
    "        \n",
    "        'linear': linear,\n",
    "        'softmax': softmax\n",
    "    }\n",
    "    \n",
    "    layers = []\n",
    "    w = []\n",
    "    b = []\n",
    "            \n",
    "    def add_layer(amount_neirons, func_activait):\n",
    "        layers.append(func_activait)\n",
    "        w.append(np.zeros(amount_neirons).reshape(amount_neirons, 1))\n",
    "        b.append(0.0)\n",
    "            \n",
    "    def MSE(y, y_pred):\n",
    "        return np.sum(np.square(y-y_pred)) / np.len(y)\n",
    "    \n",
    "    \n",
    "    y=Symbol('y')\n",
    "    y_pred=Symbol('y_pred')\n",
    "    E = np.sum(np.square(y-y_pred)) / np.len(y)\n",
    "    aa=f.diff(y)\n",
    "    aa = lambdify(y, aa)(yp)\n",
    "    return lambdify(y_pred, aa)(yp_pred)\n",
    "    \n",
    "    def predict(x):\n",
    "        h=x\n",
    "        for i in range(len(layers)):\n",
    "            t = h @ w[i] + b[i]\n",
    "            h = func_activaits[layers[i]](t)\n",
    "        return h\n",
    "    \n",
    "    def compil(X, Y, alpha)\n",
    "        #w.append(w-alpha*dE_dw)\n",
    "        #b.append(b-alpha*dE_db)    \n",
    "        \n",
    "        for i in X:\n",
    "            \n",
    "            h = []\n",
    "            t = []\n",
    "            h.append(x)\n",
    "            for i in range(len(layers)):\n",
    "                t.append(h @ w[i] + b[i])\n",
    "                h.append(func_activaits[layers[i]](t[i]))\n",
    "\n",
    "            dE_dw = []\n",
    "            dE_db = []\n",
    "            \n",
    "            dE_dh = h[len(h)-1]\n",
    "            dE_dt = Y[i] - y_pred;\n",
    "            \n",
    "            for j in range(len(w)-1, -1, 1):\n",
    "                dE_dw.append(dE_dh.T @ dE_dt)\n",
    "                dE_db.append(dE_dt)\n",
    "                dE_dh = dE_dt @ w[j]\n",
    "                dE_dt = dE_dh * func_deriv[layers[j]](t[len(w)-1-j])\n",
    "                \n",
    "            #len(dE-Dw) разворот dE\n",
    "            for j in range(len(w)-1, -1, -1):\n",
    "                w[j] = w[j] - alpha * dE_dw[len(w)-1-j];\n",
    "                b[j] = b[j] - alpha * dE_db[len(w)-1-j];\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e567410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = [0] * 5\n",
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99c91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "func_activaits = {\n",
    "    'relu': lambda t: relu(t),\n",
    "    'sigmoid': lambda t: sigmoid(t),\n",
    "    'tanh': lambda t: tanh(t),\n",
    "    'linear': lambda t: t\n",
    "}\n",
    "t = 4\n",
    "h = func_activaits['linear'](t)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33155826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perseptron:\n",
    "    \n",
    "    def relu(t):\n",
    "        return np.maximum(t,0)\n",
    "    def sigmoid(t):\n",
    "        return 1/(1+np.exp(-t))\n",
    "    def tanh(t):\n",
    "        return np.tanh(t)\n",
    "    def softmax(t):\n",
    "        out = np.exp(t)\n",
    "        return out/np.sum(out)\n",
    "    func_activaits = {\n",
    "        'relu': lambda t: relu(t),\n",
    "        'sigmoid': lambda t: sigmoid(t),\n",
    "        'tanh': lambda t: tanh(t),\n",
    "        \n",
    "        'linear': lambda t: t,\n",
    "        'softmax': lambda t: softmax(t)\n",
    "    }\n",
    "    layers=[]\n",
    "    w = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "            w.append(np.zeros(layers[i][0]).reshape(layers[i][0], 1))\n",
    "            b.append(0.0)\n",
    "            \n",
    "    def add_layer(amount_neirons, func_activait):\n",
    "        layers.append([amount_neirons, func_activait])\n",
    "    def MSE(y, y_pred):\n",
    "        return np.sum(np.square(y-y_pred)) / np.len(y)\n",
    "    def predict(x):\n",
    "        h=x\n",
    "        for i in range(len(layers)):\n",
    "            t = h @ w[i] + b[i]\n",
    "            h = func_activaits[layers[i][1]](t)\n",
    "        return h\n",
    "    def compil(X, y, alpha)\n",
    "        w.append(w-alpha*dE_dw)\n",
    "        b.append(b-alpha*dE_db)\n",
    "        for i in X:\n",
    "            y_pred = predict(i)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2b199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
